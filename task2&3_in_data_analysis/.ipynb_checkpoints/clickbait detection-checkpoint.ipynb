{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aefcfdad",
   "metadata": {},
   "source": [
    "# importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "8a83038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas  as pd\n",
    "import requests as req\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2907065",
   "metadata": {},
   "source": [
    "# *****************************PROBLEM 1 – Reading the data*************************\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6840411f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58ea9d1c",
   "metadata": {},
   "source": [
    "# urls to the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "7ffa2973",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_baits=\"https://raw.githubusercontent.com/pfrcks/clickbait-detection/master/clickbait\"\n",
    "negative_baits=\"https://raw.githubusercontent.com/pfrcks/clickbait-detection/master/not-clickbait\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15c04a4",
   "metadata": {},
   "source": [
    "# A function to fetch the data from a URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "61456203",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_read_function(url,label):\n",
    "    response=req.get(url)\n",
    "    text = response.text\n",
    "    lines = text.split('\\n')\n",
    "    df=pd.DataFrame({'baits': lines})\n",
    "    df.index.name = 'Index'\n",
    "    df['Label'] = label\n",
    "    #df.to_csv('baits_data.csv', index=False)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3846d5",
   "metadata": {},
   "source": [
    "# Read the positive and negative datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "c6666263",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "positive_dataset = my_read_function(positive_baits,'clickbait')\n",
    "negative_dataset = my_read_function(negative_baits,'not-clickbait')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f31dbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baits</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Man repairs fence to contain dog, hilarity ens...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Long-Term Marijuana Use Has One Crazy Side Eff...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The water from his ear trickles into the bucke...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You'll Never Guess What Nick Jonas Does in the...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How Cruise Liners Fill All Their Unsold Cruise...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>OITNB's Taylor Schilling and Carrie Brownstein...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>Researchers have discovered the average penis ...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>Why it may be smart to wait to put on sunscree...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>What state has highest rate of rape in the cou...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td></td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>815 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   baits      Label\n",
       "Index                                                              \n",
       "0      Man repairs fence to contain dog, hilarity ens...  clickbait\n",
       "1      Long-Term Marijuana Use Has One Crazy Side Eff...  clickbait\n",
       "2      The water from his ear trickles into the bucke...  clickbait\n",
       "3      You'll Never Guess What Nick Jonas Does in the...  clickbait\n",
       "4      How Cruise Liners Fill All Their Unsold Cruise...  clickbait\n",
       "...                                                  ...        ...\n",
       "810    OITNB's Taylor Schilling and Carrie Brownstein...  clickbait\n",
       "811    Researchers have discovered the average penis ...  clickbait\n",
       "812    Why it may be smart to wait to put on sunscree...  clickbait\n",
       "813    What state has highest rate of rape in the cou...  clickbait\n",
       "814                                                       clickbait\n",
       "\n",
       "[815 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#reading from  the positive_dataset/click_baits_dataset\n",
    "df=pd.DataFrame(positive_dataset)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "177bbd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baits</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Congress Slips CISA Into a Budget Bill That's ...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DUI Arrest Sparks Controversy</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It’s unconstitutional to ban the homeless from...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Government Error Just Revealed Snowden Was t...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A toddler got meningitis. His anti-vac parents...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>Loophole means ecstasy and loads of other drug...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>Astronomers Watch a Supernova and See Reruns</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>In Indian Rapists’ Neighborhood, Smoldering An...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>Strong earthquake jolts Islamabad</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td></td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1575 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   baits          Label\n",
       "Index                                                                  \n",
       "0      Congress Slips CISA Into a Budget Bill That's ...  not-clickbait\n",
       "1                          DUI Arrest Sparks Controversy  not-clickbait\n",
       "2      It’s unconstitutional to ban the homeless from...  not-clickbait\n",
       "3      A Government Error Just Revealed Snowden Was t...  not-clickbait\n",
       "4      A toddler got meningitis. His anti-vac parents...  not-clickbait\n",
       "...                                                  ...            ...\n",
       "1570   Loophole means ecstasy and loads of other drug...  not-clickbait\n",
       "1571        Astronomers Watch a Supernova and See Reruns  not-clickbait\n",
       "1572   In Indian Rapists’ Neighborhood, Smoldering An...  not-clickbait\n",
       "1573                   Strong earthquake jolts Islamabad  not-clickbait\n",
       "1574                                                      not-clickbait\n",
       "\n",
       "[1575 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#reading from  the positive_dataset/click_baits_dataset\n",
    "df=pd.DataFrame(negative_dataset)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690e353e",
   "metadata": {},
   "source": [
    "# Combining  the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "ce915c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_dataset = pd.concat([positive_dataset, negative_dataset], ignore_index=True)\n",
    "df=pd.DataFrame(combined_dataset)\n",
    "\n",
    "df.to_csv(\"combined.csv\",index=False) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71fa7619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baits</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Man repairs fence to contain dog, hilarity ens...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Long-Term Marijuana Use Has One Crazy Side Eff...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The water from his ear trickles into the bucke...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You'll Never Guess What Nick Jonas Does in the...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How Cruise Liners Fill All Their Unsold Cruise...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Could Queen Elizabeth Veto Brexit?</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This Is the Worst Color to Paint Your Kitchen</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Shocking Truth About Sugar</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               baits      Label\n",
       "0  Man repairs fence to contain dog, hilarity ens...  clickbait\n",
       "1  Long-Term Marijuana Use Has One Crazy Side Eff...  clickbait\n",
       "2  The water from his ear trickles into the bucke...  clickbait\n",
       "3  You'll Never Guess What Nick Jonas Does in the...  clickbait\n",
       "4  How Cruise Liners Fill All Their Unsold Cruise...  clickbait\n",
       "5                 Could Queen Elizabeth Veto Brexit?  clickbait\n",
       "6      This Is the Worst Color to Paint Your Kitchen  clickbait\n",
       "7                     The Shocking Truth About Sugar  clickbait"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#reading the first 8 rows of the combined dataset\n",
    "df.head(8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a895972",
   "metadata": {},
   "source": [
    "# Shuffling  the combined dataset using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "2755f76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Create an array of indices from 0 to the length of the combined dataset\n",
    "shuffled_indices = np.arange(len(combined_dataset))\n",
    "# Shuffle the array of indices randomly using numpy's random.shuffle function\n",
    "np.random.shuffle(shuffled_indices)\n",
    "# Use the shuffled indices to rearrange the rows of the combined dataset, creating the shuffled dataset\n",
    "shuffled_dataset = combined_dataset.iloc[shuffled_indices]\n",
    "df2=pd.DataFrame(shuffled_dataset)\n",
    "df2.to_csv(\"shuffled.csv\",index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3af547d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baits</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>You Won’t Believe What Material These Sunglass...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>Lenovo caught installing adware on new computers</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>How to tell if someone is a narcissist with on...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>Disney Donates $1 Million to Orlando Shooting ...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>Who's minding the marijuana? Banned pesticide ...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>Why did Croatia fans disrupt their Euro 2016 m...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>​Don't laugh: Google's Parsey McParseface is a...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Paul McCartney Reveals What Really Split Up th...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>Gay Chinese man sues mental hospital for tryin...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>Abercrombie &amp; Fitch is facing a terrifying rea...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  baits          Label\n",
       "356   You Won’t Believe What Material These Sunglass...      clickbait\n",
       "1671   Lenovo caught installing adware on new computers  not-clickbait\n",
       "60    How to tell if someone is a narcissist with on...      clickbait\n",
       "1339  Disney Donates $1 Million to Orlando Shooting ...  not-clickbait\n",
       "1568  Who's minding the marijuana? Banned pesticide ...  not-clickbait\n",
       "570   Why did Croatia fans disrupt their Euro 2016 m...      clickbait\n",
       "1214  ​Don't laugh: Google's Parsey McParseface is a...  not-clickbait\n",
       "309   Paul McCartney Reveals What Really Split Up th...      clickbait\n",
       "2113  Gay Chinese man sues mental hospital for tryin...  not-clickbait\n",
       "538   Abercrombie & Fitch is facing a terrifying rea...      clickbait"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#reading the first ten rows of the shuffled_dataset\n",
    "df=pd.DataFrame(shuffled_dataset)\n",
    "df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06571b4f",
   "metadata": {},
   "source": [
    "# Split the shuffled dataset into train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "b3cd3acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_data_percentage = 0.72  # 72% for training\n",
    "validation_data_percentage = 0.08  # 8% for validation\n",
    "test_data_percentage = 0.20  # 20% for testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "c15e1186",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calculate the number of samples for each split\n",
    "total_samples = len(shuffled_dataset) #number of rows in the combined dataset\n",
    "train_data_samples = int(train_data_percentage * total_samples) #number of rows in the training dataset \n",
    "validation_data_samples = int(validation_data_percentage * total_samples) #number of rows in the validation dataset\n",
    "test_data_samples = total_samples - train_data_samples - validation_data_samples #number of rows in the testing dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "5f20314f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************* OUTPUT ********************\n",
      "\n",
      "total sample or the number of rows =2390 samples/rows\n",
      "validation samples or the number of rows =191 samples/rows\n",
      "Training samples or the number of rows =1720 samples/rows\n",
      "test samples or the number of rows =479 samples/rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#printing the number of rows/ samples in each dataset\n",
    "print(\"********************* OUTPUT ********************\\n\")\n",
    "print(f\"total sample or the number of rows ={total_samples} samples/rows\")\n",
    "print(f\"validation samples or the number of rows ={validation_data_samples} samples/rows\")\n",
    "print(f\"Training samples or the number of rows ={train_data_samples} samples/rows\")\n",
    "print(f\"test samples or the number of rows ={test_data_samples} samples/rows\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "c87b3d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Spliting the dataset into training and the remaining data (remaining_data)\n",
    "training_data, remaining_data = train_test_split(shuffled_dataset, test_size=(1 - train_data_percentage))\n",
    "\n",
    "# Split the remaining data into validation and test sets\n",
    "validation_data, test_data = train_test_split(remaining_data, test_size=test_data_percentage / (test_data_percentage + validation_data_percentage))\n",
    "#saving the datasets \n",
    "train_dataset=pd.DataFrame(training_data) #training dataset\n",
    "train_dataset.to_csv(\"traning_data.csv\",index=False)\n",
    "\n",
    "validating_dataset=pd.DataFrame(validation_data) #validating  set\n",
    "validating_dataset.to_csv(\"validating_data.csv\",index=False)\n",
    "\n",
    "testing_dataset=pd.DataFrame(test_data) #testing set \n",
    "testing_dataset.to_csv('testing_dataset.csv',index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44273b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baits</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>It is rare for a new animal species to emerge ...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>Ontario parents who object to vaccines could b...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>Panama Papers: British Banker Funded North Kor...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>Burnt: 220 hives containing 250,000 bees</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>Artificial intelligence: ‘Homo sapiens will be...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>The ‘Right’ Age to Get Married</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386</th>\n",
       "      <td>Astronomers Watch a Supernova and See Reruns</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>German spy agency says ISIS sending fighters d...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>The disappeared: Chicago police detain America...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>Pregnant women warned not to travel to Rio Oly...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1720 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  baits          Label\n",
       "1187  It is rare for a new animal species to emerge ...  not-clickbait\n",
       "1701  Ontario parents who object to vaccines could b...  not-clickbait\n",
       "1673  Panama Papers: British Banker Funded North Kor...  not-clickbait\n",
       "1781           Burnt: 220 hives containing 250,000 bees  not-clickbait\n",
       "2014  Artificial intelligence: ‘Homo sapiens will be...  not-clickbait\n",
       "...                                                 ...            ...\n",
       "436                      The ‘Right’ Age to Get Married      clickbait\n",
       "2386       Astronomers Watch a Supernova and See Reruns  not-clickbait\n",
       "2324  German spy agency says ISIS sending fighters d...  not-clickbait\n",
       "992   The disappeared: Chicago police detain America...  not-clickbait\n",
       "1702  Pregnant women warned not to travel to Rio Oly...  not-clickbait\n",
       "\n",
       "[1720 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#reading from each and every dataset after split\n",
    "train_dataset #reading from the training dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc9a59a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baits</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>Only 3 northern white rhinos left on Earth</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>Trump's campaign cycles $6 million into Trump ...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>Top UN Official Says 'Global War on Terror' Is...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>Kerry calls for democracy in Cuba as U.S. flag...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>Knife turned into police allegedly found on O....</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>Proposed California Ballot Initiative That Wou...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Here's what those floaty things in your eyes are</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>FIFA scandal: Sepp Blatter wins another term a...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>A Waterfall in the Middle of a Lake</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>Ikea vows to be net exporter of renewable ener...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>479 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  baits          Label\n",
       "1873         Only 3 northern white rhinos left on Earth  not-clickbait\n",
       "701   Trump's campaign cycles $6 million into Trump ...      clickbait\n",
       "2366  Top UN Official Says 'Global War on Terror' Is...  not-clickbait\n",
       "1698  Kerry calls for democracy in Cuba as U.S. flag...  not-clickbait\n",
       "1032  Knife turned into police allegedly found on O....  not-clickbait\n",
       "...                                                 ...            ...\n",
       "1456  Proposed California Ballot Initiative That Wou...  not-clickbait\n",
       "22     Here's what those floaty things in your eyes are      clickbait\n",
       "2168  FIFA scandal: Sepp Blatter wins another term a...  not-clickbait\n",
       "655                 A Waterfall in the Middle of a Lake      clickbait\n",
       "2131  Ikea vows to be net exporter of renewable ener...  not-clickbait\n",
       "\n",
       "[479 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#reading from the testing dataset\n",
    "testing_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4724c679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baits</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Why Has Mark Zuckerberg Put Tape Over His Camera?</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>Dad And Son Are Seconds From Assassination By ...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>Martin Shkreli fired as CEO of KaloBios Pharma...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>Former Brazilian soccer star: Don't come to th...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Guess how much Google paid the guy who briefly...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248</th>\n",
       "      <td>Stop refugees or we'll stop aid, Germany tells...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>Guess Who’s Complaining About Obama’s New Over...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>Saudi Arabia insists UN keeps LGBT rights out ...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>Napolitano Says ‘We Don’t Have To Listen To Th...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>Vladimir Putin says the Panama Papers are part...</td>\n",
       "      <td>not-clickbait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  baits          Label\n",
       "382   Why Has Mark Zuckerberg Put Tape Over His Camera?      clickbait\n",
       "628   Dad And Son Are Seconds From Assassination By ...      clickbait\n",
       "1125  Martin Shkreli fired as CEO of KaloBios Pharma...  not-clickbait\n",
       "1935  Former Brazilian soccer star: Don't come to th...  not-clickbait\n",
       "363   Guess how much Google paid the guy who briefly...      clickbait\n",
       "...                                                 ...            ...\n",
       "2248  Stop refugees or we'll stop aid, Germany tells...  not-clickbait\n",
       "574   Guess Who’s Complaining About Obama’s New Over...      clickbait\n",
       "2042  Saudi Arabia insists UN keeps LGBT rights out ...  not-clickbait\n",
       "1321  Napolitano Says ‘We Don’t Have To Listen To Th...  not-clickbait\n",
       "1123  Vladimir Putin says the Panama Papers are part...  not-clickbait\n",
       "\n",
       "[191 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#reading from the validation  dataset\n",
    "validating_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdc31e1",
   "metadata": {},
   "source": [
    "# Calculating the \"target rate\" for each dataset (training,validation and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "014e9086",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_data_target_rate = (train_dataset['Label'] == 'clickbait').mean()\n",
    "validation_data_target_rate = (validating_dataset['Label'] == 'clickbait').mean()\n",
    "test_data_target_rate = (testing_dataset['Label'] == 'clickbait').mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f67be6a",
   "metadata": {},
   "source": [
    "# what % of the three datasets is t is labeled as clickbait?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "8695054c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************* OUTPUT ********************\n",
      "\n",
      "34.36% of the training data is labeled as clickbait\n",
      "35.08% of the validating data is labeled as clickbait\n",
      "32.78% of the testing data is labeled as clickbait\n"
     ]
    }
   ],
   "source": [
    "print(\"********************* OUTPUT ********************\\n\")\n",
    "print(f\"{train_data_target_rate.round(4)*100}% of the training data is labeled as clickbait\")\n",
    "print(f\"{validation_data_target_rate.round(4)*100}% of the validating data is labeled as clickbait\")\n",
    "print(f\"{test_data_target_rate.round(4)*100}% of the testing data is labeled as clickbait\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac7013a",
   "metadata": {},
   "source": [
    "# **********************  PROBLEM 3 – Training a single Bag-of-Words (BOW) Text Classifier ***************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "7df9cbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Loading the training and validation datasets\n",
    "validating_dataset  #the dataset containing the validating data\n",
    "train_dataset #the dataset containing the traingin data\n",
    "\n",
    "\n",
    "# Map labels to binary values (1 for clickbait, 0 for non-clickbait)\n",
    "train_dataset['Label'] = (train_dataset['Label'] == 'clickbait').astype(int)\n",
    "validating_dataset['Label'] = (validating_dataset['Label'] == 'clickbait').astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# Creating  a Pipeline with CountVectorizer and MultinomialNB\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(ngram_range=(1, 2))),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "\n",
    "# Fiting  the classifier on the training dataset\n",
    "pipeline.fit(train_dataset['baits'], train_dataset['Label'])\n",
    "\n",
    "\n",
    "# Predict on the training and validation datasets\n",
    "train_predictions = pipeline.predict(train_dataset['baits'])\n",
    "validation_predictions = pipeline.predict(validating_dataset['baits'])\n",
    "\n",
    "\n",
    "\n",
    "# Computing  precision, recall, and F1-score for training and validation datasets with zero_division='warn'\n",
    "train_precision = precision_score(train_dataset['Label'], train_predictions, pos_label=1, zero_division='warn')\n",
    "train_recall = recall_score(train_dataset['Label'], train_predictions, pos_label=1, zero_division='warn')\n",
    "train_f1 = f1_score(train_dataset['Label'], train_predictions, pos_label=1, zero_division='warn')\n",
    "\n",
    "validation_precision = precision_score(validating_dataset['Label'], validation_predictions, pos_label=1, zero_division='warn')\n",
    "validation_recall = recall_score(validating_dataset['Label'], validation_predictions, pos_label=1, zero_division='warn')\n",
    "validation_f1 = f1_score(validating_dataset['Label'], validation_predictions, pos_label=1, zero_division='warn')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "4dabbaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************* OUTPUT ********************\n",
      "\n",
      "Training Precision is  0.9915966386554622  or  99.16%\n",
      "Training Recall is 0.9983079526226735  or 99.83%\n",
      "Training F1-score is  0.9949409780775718 or 99.83%\n",
      "\n",
      "\n",
      "Validation Precision is 0.8615384615384616 or 86.15% \n",
      "Validation Recall is  0.835820895522388 or 86.15%\n",
      "Validation F1-score is 0.8484848484848485 or 84.85000000000001%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Print the results\n",
    "print(\"********************* OUTPUT ********************\\n\")\n",
    "print(f\"Training Precision is  {train_precision}  or  {train_precision.round(4)*100}%\")\n",
    "print(f\"Training Recall is {train_recall}  or {train_recall.round(4)*100}%\")\n",
    "print(f\"Training F1-score is  {train_f1} or {train_recall.round(4)*100}%\")\n",
    "print(\"\\n\")\n",
    "print(f\"Validation Precision is {validation_precision} or {validation_precision.round(4)*100}% \")\n",
    "print(f\"Validation Recall is  {validation_recall} or {validation_precision.round(4)*100}%\")\n",
    "print(f\"Validation F1-score is { validation_f1} or {validation_f1.round(4)*100}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11002a17",
   "metadata": {},
   "source": [
    "# ********************** PROBLEM 4 – Hyperparameter Tuning**********************\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "fed41b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************* OUTPUT ********************\n",
      "\n",
      "Top Results\n",
      "                                               params  validation_precision  \\\n",
      "0   {'classifier__alpha': 1.0, 'vectorizer__max_df...                   1.0   \n",
      "1   {'classifier__alpha': 1.0, 'vectorizer__max_df...                   1.0   \n",
      "16  {'classifier__alpha': 0.1, 'vectorizer__max_df...                   1.0   \n",
      "15  {'classifier__alpha': 0.1, 'vectorizer__max_df...                   1.0   \n",
      "14  {'classifier__alpha': 0.1, 'vectorizer__max_df...                   1.0   \n",
      "\n",
      "    validation_recall  validation_f1  \n",
      "0                 1.0            1.0  \n",
      "1                 1.0            1.0  \n",
      "16                1.0            1.0  \n",
      "15                1.0            1.0  \n",
      "14                1.0            1.0  \n",
      "Bottom Results\n",
      "                                               params  validation_precision  \\\n",
      "5   {'classifier__alpha': 1.0, 'vectorizer__max_df...                   1.0   \n",
      "4   {'classifier__alpha': 1.0, 'vectorizer__max_df...                   1.0   \n",
      "3   {'classifier__alpha': 1.0, 'vectorizer__max_df...                   1.0   \n",
      "2   {'classifier__alpha': 1.0, 'vectorizer__max_df...                   1.0   \n",
      "17  {'classifier__alpha': 0.1, 'vectorizer__max_df...                   1.0   \n",
      "\n",
      "    validation_recall  validation_f1  \n",
      "5                 1.0            1.0  \n",
      "4                 1.0            1.0  \n",
      "3                 1.0            1.0  \n",
      "2                 1.0            1.0  \n",
      "17                1.0            1.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Mapping  labels to binary values (1 for clickbait, 0 for non-clickbait)\n",
    "train_dataset['Label'] = (train_dataset['Label'] == 'clickbait').astype(int)\n",
    "validating_dataset['Label'] = (validating_dataset['Label'] == 'clickbait').astype(int)\n",
    "\n",
    "\n",
    "# Defining a grid of hyperparameters to search\n",
    "parameter_grid = {\n",
    "    'vectorizer__max_df': [0.5, 0.75, 1.0],  # Vary max_df for CountVectorizer\n",
    "    'classifier__alpha': [1.0, 0.5, 0.1],     # Vary smoothing for MultinomialNB\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)]  # Include or exclude bigrams in CountVectorizer\n",
    "}\n",
    "\n",
    "\n",
    "# Initializing  an empty  list to store the results\n",
    "results = []\n",
    "\n",
    "\n",
    "# Iterating  over the parameter grid\n",
    "for params in ParameterGrid(parameter_grid):\n",
    "    # Creating  a Pipeline with CountVectorizer and MultinomialNB with the current parameters\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', CountVectorizer(max_df=params['vectorizer__max_df'], ngram_range=params['vectorizer__ngram_range'])),\n",
    "        ('classifier', MultinomialNB(alpha=params['classifier__alpha']))\n",
    "    ])\n",
    "    \n",
    "\n",
    "    # Fiting  the classifier on the training dataset\n",
    "    pipeline.fit(train_dataset['baits'], train_dataset['Label'])\n",
    "\n",
    "    \n",
    "    # Predicting  on the validation dataset\n",
    "    validation_predictions = pipeline.predict(validating_dataset['baits'])\n",
    "\n",
    "    \n",
    "    # Computing  precision, recall, and F1-score for validation dataset\n",
    "    validation_precision = precision_score(validating_dataset['Label'], validation_predictions,zero_division=1)\n",
    "    validation_recall = recall_score(validating_dataset['Label'], validation_predictions,zero_division=1)\n",
    "    validation_f1 = f1_score(validating_dataset['Label'], validation_predictions,zero_division=1)\n",
    "\n",
    "    \n",
    "    # Storing  the results\n",
    "    results.append({\n",
    "        'params': params,\n",
    "        'validation_precision': validation_precision,\n",
    "        'validation_recall': validation_recall,\n",
    "        'validation_f1': validation_f1\n",
    "    })\n",
    "\n",
    "# Converting  results to a DataFrame for analysis\n",
    "results_dataframe = pd.DataFrame(results)\n",
    "\n",
    "# Sorting  the results by F1-score in descending order\n",
    "results_dataframe = results_dataframe.sort_values(by='validation_f1', ascending=False)\n",
    "\n",
    "# Displaying  the top and bottom results \n",
    "print(\"********************* OUTPUT ********************\\n\")\n",
    "print(\"Top Results\")\n",
    "print(results_dataframe.head())\n",
    "print(\"Bottom Results\")\n",
    "print(results_dataframe.tail())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03e1519",
   "metadata": {},
   "source": [
    "# *********************************PROBLEM 5 – Model selection ************************\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "251f7a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************* OUTPUT ********************\n",
      "\n",
      "Best Model - Parameters \n",
      "{'classifier__alpha': 1.0, 'vectorizer__max_df': 0.5, 'vectorizer__ngram_range': (1, 1)}\n",
      "\n",
      "\n",
      " Validation F1-Score value  of  the Best Model is  1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#To select the best model from the results of the hyperparameter tuning,\n",
    "#i choose the one that achieved the highest F1-score on the validation set. how do choose.\n",
    "\n",
    "\n",
    "# Finding  the best model based on validation F1-score values\n",
    "best_model = max(results, key=lambda x: x['validation_f1'])\n",
    "\n",
    "# Displaying  the best model's parameters and validation F1-score  value\n",
    "print(\"********************* OUTPUT ********************\\n\")\n",
    "print(\"Best Model - Parameters \")\n",
    "print(best_model['params'])\n",
    "print(\"\\n\")\n",
    "print(\" Validation F1-Score value  of  the Best Model is \", best_model['validation_f1'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "2e2061a0",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "    \n",
    "#applying the  model to my  test set and computing the  precision, recall, and F1-score values\n",
    "    \n",
    "   # Creating  a pipeline with the best model's parameters\n",
    "best_model_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(max_df=best_model['params']['vectorizer__max_df'], ngram_range=best_model['params']['vectorizer__ngram_range'])),\n",
    "    ('classifier', MultinomialNB(alpha=best_model['params']['classifier__alpha']))\n",
    "])\n",
    "\n",
    "# Fiting my  best model on the training dataset\n",
    "best_model_pipeline.fit(train_dataset['baits'], train_dataset['Label'])\n",
    "\n",
    "# Predicting  on the test dataset\n",
    "test_predictions = best_model_pipeline.predict(testing_dataset['baits'])\n",
    "\n",
    "#removing posible NAN values\n",
    "clean_testing_data = testing_dataset.dropna()\n",
    "\n",
    "# Convert true labels to numeric format\n",
    "clean_testing_data['Label'] = clean_testing_data['Label'].map({'clickbait': 1, 'not-clickbait': 0})\n",
    "\n",
    "# Computing the  precision, recall, and F1-score values  for the test dataset\n",
    "test_precision = precision_score(clean_testing_data['Label'], test_predictions,zero_division=1)\n",
    "test_recall = recall_score(clean_testing_data['Label'], test_predictions)\n",
    "test_f1 = f1_score(clean_testing_data['Label'], test_predictions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "6cde08ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************* OUTPUT ********************\n",
      "\n",
      "These are Test Set Metrics for Best Model \n",
      "Precision  1.0\n",
      "Recall  0.0\n",
      "F1-Score  0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"********************* OUTPUT ********************\\n\")\n",
    "# Display the test set results\n",
    "print(\"These are Test Set Metrics for Best Model \")\n",
    "print(\"Precision \", test_precision)\n",
    "print(\"Recall \", test_recall)\n",
    "print(\"F1-Score \" , test_f1)\n",
    " \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc05a044",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a060e973",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b84f8f9",
   "metadata": {},
   "source": [
    "# ************************PROBLEM 6 – Key Indicators*********************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0986df59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Convert the text to lowercase to ensure consistency.\n",
    "train_dataset['baits'] = train_dataset['baits'].str.lower()\n",
    "\n",
    "\n",
    "\n",
    "# Defining  a dictionary to map labels to binary values\n",
    "label_mapping = {'clickbait': 1, 'not-clickbait': 0} # Mapping  labels to binary values (1 for clickbait, 0 for non-clickbait)\n",
    "\n",
    "\n",
    "\n",
    "# Using  the map method to update my  'Label' column\n",
    "train_dataset['Label'] = train_dataset['Label'].map(label_mapping)\n",
    "\n",
    "\n",
    "\n",
    "# Creating  a CountVectorizer to extract key words\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2)) \n",
    "\n",
    "\n",
    "# Transforming  the training data into a feature matrix\n",
    "X_train = vectorizer.fit_transform(train_dataset['baits'])\n",
    "\n",
    "\n",
    "# Initializing  and training  a Multinomial Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, train_dataset['Label'])\n",
    "\n",
    "\n",
    "# Geting  the feature log probabilities for the \"clickbait\" class\n",
    "clickbait_log_probs = clf.feature_log_prob_[1]\n",
    "\n",
    "\n",
    "# Geting the corresponding vocabulary words\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "\n",
    "\n",
    "# Creating  a DataFrame to analyze the results\n",
    "clickbait_dataframe = pd.DataFrame({'Word': feature_names, 'Log Probability': clickbait_log_probs})\n",
    "\n",
    "\n",
    "# Sorting  the DataFrame by log probability in descending order\n",
    "clickbait_dataframe = clickbait_dataframe.sort_values(by='Log Probability', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "c89ab08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************* OUTPUT ********************\n",
      "\n",
      "Top 5 Clickbait Indicator Words\n",
      "       Word  Log Probability\n",
      "16995   the        -4.851182\n",
      "20060   you        -5.373704\n",
      "17625    to        -5.462499\n",
      "17409  this        -5.521340\n",
      "9028     is        -5.567860\n",
      "11905    of        -5.789021\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Display the top 5 words with the highest log probability\n",
    "top_clickbait_words = clickbait_dataframe.head(6)\n",
    "print(\"********************* OUTPUT ********************\\n\")\n",
    "print(\"Top 5 Clickbait Indicator Words\")\n",
    "print(top_clickbait_words)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c477e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf5873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2d48c8",
   "metadata": {},
   "source": [
    "# ************** PROBLEM 7 – Regular expression *************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d51a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeae447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "4d31aa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************* OUTPUT ********************\n",
      "\n",
      "Keyword found in the text.\n"
     ]
    }
   ],
   "source": [
    "# A list of words that are recognized as clickbaits in the previous Question\n",
    "top_keywords = top_clickbait_words['Word'].unique()\n",
    "\n",
    "# Constructing  a regular expression pattern to match any of the top keywords with word boundaries\n",
    "pattern = r'\\b(?:' + '|'.join(re.escape(keyword) for keyword in top_keywords) + r')\\b'\n",
    "\n",
    "#A testing message\n",
    "text = \"you will be a billionaire within two days if you do the following. Follow this steps .\"\n",
    "print(\"********************* OUTPUT ********************\\n\")\n",
    "# Using  re.search function to find matches in the text\n",
    "if re.search(pattern, text):\n",
    "    print(\"Keyword found in the text.\")\n",
    "else:\n",
    "    print(\"Keyword not found in the text.\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8689fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "f25851e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing any nans\n",
    "\n",
    "testing_dataset=testing_dataset.dropna()\n",
    "\n",
    "\n",
    "\n",
    "# Defining  a dictionary to map labels to binary values\n",
    "label_mapping = {'clickbait': 1, 'not-clickbait': 0} # Mapping  labels to binary values (1 for clickbait, 0 for non-clickbait)\n",
    "\n",
    "\n",
    "# Using  the map method to update my  'Label' column\n",
    "testing_dataset['Label'] = testing_dataset['Label'].map(label_mapping)\n",
    "\n",
    "\n",
    "\n",
    "# Creating a function  to check if any top keywords are present in the text from the test data_set\n",
    "def keyword_classifier(text):\n",
    "    pattern = r'\\b(?:' + '|'.join(re.escape(keyword) for keyword in top_keywords) + r')\\b'\n",
    "    return bool(re.search(pattern, text))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Applying  the function to  test_dataset \n",
    "\n",
    "testing_dataset['Predicted'] = testing_dataset['baits'].apply(keyword_classifier)\n",
    "\n",
    "\n",
    "\n",
    "# Calculating the  precision and recall values \n",
    "\n",
    "precision = precision_score(testing_dataset['Label'], testing_dataset['Predicted'], zero_division='warn')\n",
    "\n",
    "recall = recall_score(testing_dataset['Label'], testing_dataset['Predicted'], zero_division='warn')\n",
    "\n",
    "f1=f1_score(testing_dataset['Label'], testing_dataset['Predicted'], zero_division='warn')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7095d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "e0d0441b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************* OUTPUT ********************\n",
      "\n",
      "The Precision of this classifier is 0.32589285714285715 or  32.59%\n",
      "The Recall of this classifier is  0.46496815286624205 or  46.5%\n",
      "The Recall of this classifier is  0.3832020997375329 or  38.32%\n"
     ]
    }
   ],
   "source": [
    "#printing the results \n",
    "print(\"********************* OUTPUT ********************\\n\")\n",
    "print(f\"The Precision of this classifier is {precision} or  {precision.round(4)*100}%\")\n",
    "print(f\"The Recall of this classifier is  {recall} or  {recall.round(4)*100}%\")\n",
    "print(f\"The Recall of this classifier is  {f1} or  {f1.round(4)*100}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
